{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = np.load(\"/Users/tangqie/Desktop/cs541/hw3/mnist_train_images.npy\")\n",
    "tr_y = np.load(\"/Users/tangqie/Desktop/cs541/hw3/mnist_train_labels.npy\")\n",
    "valid_x = np.load(\"/Users/tangqie/Desktop/cs541/hw3/mnist_validation_images.npy\")\n",
    "valida_y = np.load(\"/Users/tangqie/Desktop/cs541/hw3/mnist_validation_labels.npy\")\n",
    "te_x = np.load(\"/Users/tangqie/Desktop/cs541/hw3/mnist_test_images.npy\")\n",
    "te_y = np.load(\"/Users/tangqie/Desktop/cs541/hw3/mnist_test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(w,x):\n",
    "    yh = np.exp(x@w.T)\n",
    "    yh_total = np.sum(yh)\n",
    "    return yh/yh_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_true,w,alpha,x):\n",
    "    yh = softmax(w,x)\n",
    "    n = y_true.shape[0]\n",
    "    loss = (-1/n)*np.sum(y_true*np.log(yh))+(alpha/2)*np.sum(np.multiply(w,w))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x,y_true,w,alpha):\n",
    "    yh = softmax(x,w)\n",
    "    grad = -(1/x.shape[0])*(x.T.dot(y_true -yh.T)).T + alpha * w\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(batch,rate,epochs,alpha,x,y):\n",
    "    n = y.shape[0]\n",
    "    np.random.seed(2020)\n",
    "    np.random.shuffle(x)\n",
    "    np.random.seed(2020)\n",
    "    np.random.shuffle(y)\n",
    "    w = np.random.randn(y.shape[1],x.shape[1])\n",
    "    ploss = 0\n",
    "    loss = cost(y,w,alpha,x)\n",
    "    for i in range(epochs):\n",
    "        ploss = loss\n",
    "        for j in range(int(n/batch)):\n",
    "            tr_x = x[j*batch:(j+1)*batch,:]\n",
    "            tr_y = y[j*batch:(j+1)*batch,:]\n",
    "            fce = grad(x,y,w,alpha)\n",
    "            w = w-rate*fce\n",
    "        loss = cost(y,w,alpha,x)\n",
    "        if (np.abs(loss-ploss)<0.01):\n",
    "            return w,loss\n",
    "    return w,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(yh, y):\n",
    "    falseNum = np.count_nonzero(np.argmax(yh, axis = 1) -  np.argmax(y, axis = 1))\n",
    "    return (y.shape[0] - falseNum)/ y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = SGD(5000,0.06,100,0.04,tr_x,tr_y)\n",
    "accu = accuracy(valid_x@w.T, valida_y)\n",
    "print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
