{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (60000, 28, 28) train_labels shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(\"train_images shape:\", train_images.shape, \"train_labels shape:\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a098d1ae88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show one of the images from the training dataset\n",
    "img_index = 2020\n",
    "plt.imshow(train_images[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = train_images[0:10000]\n",
    "val_labels = train_labels[0:10000]\n",
    "train_images = train_images[10000:]\n",
    "train_labels = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = val_images.reshape((val_images.shape[0], 28, 28, 1))\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = to_categorical(val_labels)\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               1327360   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,330,570\n",
      "Trainable params: 1,330,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.1304 - accuracy: 0.9507 - val_loss: 0.2242 - val_accuracy: 0.9272\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.1281 - accuracy: 0.9516 - val_loss: 0.2293 - val_accuracy: 0.9255\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.1251 - accuracy: 0.9524 - val_loss: 0.2206 - val_accuracy: 0.9262\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 5s 99us/sample - loss: 0.1259 - accuracy: 0.9520 - val_loss: 0.2291 - val_accuracy: 0.9266\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.1247 - accuracy: 0.9525 - val_loss: 0.2281 - val_accuracy: 0.9287\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.1200 - accuracy: 0.9546 - val_loss: 0.2235 - val_accuracy: 0.9276\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 3s 55us/sample - loss: 0.1198 - accuracy: 0.9553 - val_loss: 0.2360 - val_accuracy: 0.9266\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 3s 54us/sample - loss: 0.1165 - accuracy: 0.9556 - val_loss: 0.2557 - val_accuracy: 0.9256\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 0.1167 - accuracy: 0.9556 - val_loss: 0.2380 - val_accuracy: 0.9283\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 3s 57us/sample - loss: 0.1150 - accuracy: 0.9570 - val_loss: 0.2334 - val_accuracy: 0.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2cf57f648>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(train_images,\n",
    "          train_labels,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9284\n"
     ]
    }
   ],
   "source": [
    "print(score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
